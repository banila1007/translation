## 동시성

### Mechanics [재방문 :직역 및 의역의 문제]

#### 고루틴(Goroutine)

##### Go 스케줄러 내부

Go로 제작된 프로그램이 시작될때 사용 가능한 코어수를 확인합니다. 그리고 논리 프로세서를 생성 합니다.

운영체제 스케줄러는 선점형 스케줄러로 간주되며, 이는 커널에서 실행 됩니다. 그 역할은 실행 가능한 상태에 있는 모든 스레드를 살펴보고 일부 코어에서 실행할 수 있는 기회를 제공 하는 것입니다. 이러한 알고리즘은 상당히 복잡합니다(대기, 스레드 바운싱, 스레드 메모리 유지, 캐싱등). 이 모든 작업을 운영체제가 수행 하며 이를 위한 알고리즘은 멀티 코어 프로세서에서 영리합니다.[재방문: 잘 처리 한다]. Go는 바퀴를 재발명 하지 않기 위하여 운영체제의 최상단에 위치 하여, 이를 활용 합니다.

운영 체제는 여전히 운영 체제 스레드를 담당하고 이를 효율적으로 스케쥴링합니다. 2개의 코어 머신에서 수천게의 쓰레드가 동작하는 것은 꽤 큰 작업입니다[재방문]. 일부 운영체제에서는 컨텍스트 스위칭 대상 쓰레드가 어떤 작업을 수행 하는지에 대한 정보[재방문: 단서]가 없어 해당 작업에 비용이 상딩히 큽니다.

컨텍스트 스위칭시 가능한 쓰레드의 모든 상태를 저장해야 그 상태를 그대로 복원 할 수 있습니다. 스레드 수가 적을 경우 각 스레드별로 더 많은 실행 시간[재방문: 스케쥴될 기회]을 가질 수 있습니다. 스레드가 더 많으면 각 스레드는 오랜 기간 동안 대기 되며, 더 적은 실행 시간을 갖습니다.

컨커런트 소프트웨어[재방문: 저절한 번역문이 무엇일까]에서는 "과유불급[재방문: 적은 것으로 많은 것을 하는것]"이 정말 중요한 컨셉 입니다. Go의 스케쥴러는 선점형 스케쥴러의 이점을 활용하기 위하여, 어플리케이션이 동작하는 중 논리 프로세서는 사용자 모드(user mode)에서 실행 됩니다. 이런 이유로 Go의 스케줄러를 협력 스케줄러라고 불러야합니다. 여기서 주목할 점은 실행시간(runtime)을 조정하는 작업 입니다. 이것은 여전히 사용자 영역에서는 선점 형 스케줄러로 보입니다. "적은 것이 더 많다"라는 개념이 어떻게 나타나고 적은 비용으로 더 많은 작업을 수행 할 수 있는지 살펴볼 것입니다. 우리의 목표는 더 적은 수의 스레드로 얼마나 많은 작업을 수행하는지가 되어야 합니다.

하이퍼쓰레딩, 코어당 다수의 쓰레드,클록 주기들의 개념은 복잡하기 때문에, 이를 간단하게 다음과 같이 생각해 봅시다. 주어진 코어당 한번에 하나의 운영 체제 스레드만 실행 할 수 있습니다. 만약 하나의 코어만 있다면, 한번에 하나의 스레드만을 실행 할 수 있습니다. 실행 가능한 상태의 스레드가 소유한 코어보다 더 많으면 항상 부하, 실행 지연이 발생 하고, 우리가 원하는 것보다 더 많은 작업을 수행 하게 됩니다. 모든 스레드가 반드시 동시에 활성화되는 것은 아니기 때문에 이러한 작업은 균형을 잡는 것이 필요 합니다. 이러한 모든 것은 우리가 작성하고 있는 소프트웨어의 작업량을 알아내고, 이해하는 것으로 귀결된다. 첫 번째 아이디어로 돌아가서, Go 프로그램이 시작되면(comes up) 사용 가능한 코어수를 확인 해야 합니다. 이를 1개 라고 합시다. 그러면 해당 코어에 논리 프로세스 P가 생성 됩니다.

다시 말하지만, 운영체제는 운영체제 스레드를 중심으로 스케쥴링 합니다. m은 머신[재방문: 코어]을 나타내며, 프로세서 P는 m(머신)을 할당받고 이는 운영체제 시스템 쓰레드이며, 운영체제가 이를 스케쥴하고, 코드가 실행 될 수 있도록 합니다.

Linux 스케쥴러에는 실행 대기열이 있습니다. 스레드는 특정 코어 또는 코어 제품군의 실행 대기열에 배치되며 스레드가 실행될 때 지속적으로 바인딩됩니다. Go도 동일한 작업을 수행 합니다. Go에는 실행 대기열도 있습니다. GRQ (Global Run Queue)가 있고 모든 P에는 LRQ (Local Run Queue)가 있습니다.

##### 고루틴

고루틴은 실행 경로 이며, 스레드 또한 실행 경로 입니다. 실행 경로는 스케쥴링이 필요합니다. Go에서는 모든 함수와 메소드는 고루틴으로 생성 될 수 있으며, 이들은 모두 코어에 할당되는[재방문] 운영체제 시스템 스레드를 통해 스케쥴링 되는 독립적인 실행 경로를 가질 수 있다. [재방문: 즉 고루틴이 시스템 스레드를 통해 실행 된다는 말인것 같은데... 말로 표현하기 힘드내..] 

Go 프로그램을 시작할 때 런타임에서 가장 먼저 할 일은 고루틴을 만들고 일부 P에 대한 주요 LRQ에 넣는 것입니다. 우리의 경우에는 여기에 P가 1 개만 있으므로 고루틴이 P에 연결되어 있다고 생각할 수 있습니다.

고루틴은 스레드와 같이 세가지(슬립, 실행중, 실행 가능)상태 중 하나일 수 있습니다. 실행시간에 고루틴이 생성되면, P에 위치(할당?)되고, 해당 스레드에서 다중화[재방문: 동시 실행] 됩니다. 스레드를 스케쥴링하고 코어에 배치하고 실행 하는 것은 운영체제라는 것을 기억하세요. 따라서 Go 스케줄러는 해당 고루틴의 실행 경로와 관련된 모든 코드를 가져 와서 스레드에 배치하고 운영 체제가 대상 스레드가 실행 가능한 상태이며 실행할 수 있음을 알려줍니다. 대답이 예이면 운영 체제가 하드웨어의 일부 코어에서 실행되기 시작합니다.

매인 고루틴이 실행 중에는 추가 실행 경로나, 고루틴을 생성 하려 할 수 있습니다.

그 시점에 해당 고루틴은 처음에는 자신을 GRQ에서 찾을 수 있습니다. 이들은 실행 가능한 상태에 있지만, 아직 P에 할당되지 않은 고루틴입니다. 결국 그들은 LRQ에 할당되고, 실행 시간을 요청 하게 됩니다.

이 대기열은 선입선출(FIFO) 규칙을 무조건 따르진 않습니다. 여기에있는 모든것[재방문]이 운영체제 스케줄러처럼 비 결정적이라는 것을 이해 해야 합니다. 모든 조건[재방문: 것]이 동일할 때 스케줄러가 무엇을 수행할지 예측할 수 없습니다. 우리가 이러한 고루틴의 실행에 대한 조정하는 방법을 배워 오케스트레이션[재방문]을 할 수 있을 때 까지는 예측이 불가능 합니다.

아래의 도표는 이에 대한 예제를 표현한 맨탈모델[재방문]입니다.

![117-1](../diagrams/117-1.jpg)

P라는 스레드에 Gm이 실행 되고 있고, G1과 G2라는 고루틴을 생성 하고 있습니다. 이는 협조적 스케쥴러이므로, 이 고루틴들은 운영체제 스레드인 m위에서 서로 스케쥴되고 컨텍스트 스위칭이 되어야 합니다.

우리 코드에는 스케줄러가 스케줄링 결정을 내릴 기회가 있는 4가지 상황이 있습니다.[재방문]

- go 키워드를 통해 고루틴들을 생성할 때. 이는 여러개의 P를 가지고 있을 때, 스케줄러가 균형을 다시 맞출 수 있는 기회이기도 합니다.
- 시스템 콜. 시스템 콜은 항상 발생 하는 경향이 있습니다.
- 채널 작업. 채널 작업에는 뮤택스(동기화 호출)가 존재 합니다.
- 가비지 컬렉션.

예를 들어, 스케줄러는 Gm이 실행하기에 충분한 시간이 있다고 결정할 수 있으며 Gm을 실행 대기열에 다시 넣고 G1이 해당 m에서 실행되도록 허용합니다. 이제 컨텍스트 전환이 있습니다.

![117-2](../diagrams/117-2.jpg)

Let's say G1 decides to open up a file. Opening up a file can take microseconds or 10 milliseconds. We don't really know. If we allow this Goroutine to block this operating system thread while we open up that file, we are not getting more work done. In this scenario here, having a single P, we have a single threaded software application. All Goroutines only execute on the m attached to this P. What happens is this Goroutine is gonna block this m for a long time. We are basically stalled while we still have work that needs to get done. So the scheduler is not gonna allow that to happen, What actually happens is that the scheduler is gonna detach that m and G1. It is gonna bring a new m, say m2, then decide what G from the run queue should run next, say G2.

![118-1](../diagrams/118.jpg)

We now have 2 threads in a single threaded program. From our perspective, we are still single threading because the code that we are writing, the code associated with any G can only run against this P and this m. However, we don't know at any given time what m we are running on. M can get swapped out but we are still single threaded.

Eventually, G1 will come back, the file will be opened. The scheduler is gonna take this G1 and put it back to the run queue so we can be executed again on this P for some m (m2 in this case). m is placed on the side for later use. We are still maintaining these 2 threads. The whole process can happen again.

![119-1](../diagrams/119-1.jpg)

It is a really brilliant system of trying to leverage this thread to its fullest capability by doing more on 1 thread. Let's do so much on this thread we don't need another.

There is something called a Network poller. It is gonna do all the low level networking asynchronous networking stuff. Our G, if it is gonna do anything like that, it might be moved out to the Network poller and then brought back in. From our perspective, here is what we have to remember: The code that we are writing always runs on some P against some m. Depending on how many P we have, that's how many threads variables for us to run.

Concurrency is about managing a lot of things at once. This is what the scheduler is doing. It manages the execution of these 3 Goroutines against this one m for this P. Only 1 Goroutine can be executed at a single time.
If we want to do something in parallel, which means doing a lot of things at once, then we would need to create another P that has another m, say m3.

![119-2](../diagrams/119-2.jpg)

Both are scheduled by the operating system. So now we can have 2 Goroutines running at the same time in parallel.

Let's try another example.

We have multiple threaded software. The program launched 2 threads. Even if both threads end up on the same core, each wants to pass a message to each other. What has to happen from the operating system point of view?

We have to wait for thread 1 to get scheduled and placed on some cores - a context switch (CTX) has to happen here. While that's happening, thread is asleep so it's not running at all. From thread 1, we send a message over and want to wait to get a message back. In order to do that, there is another context switch needs to happen because we can put a different thread on that core. We are waiting for the operating system to schedule thread 2 so we are going to get another context switch, waking up and running, processing the message and sending the message back. On every single message that we are passing back and forth, thread is going from executable state to runnable state to asleep state. This is gonna cost a lot of context switches to occur.

Let's see what happens when we are using Goroutines, even on a single core.
G1 wants to send a message to G2 and we perform a context switch. However, the context here is the user's space switch. G1 can be taken out of the thread and G2 can be put on the thread. From the operating system point of view, this thread never goes to sleep. This thread is always executing and never needed to be context switched out. It is the Go's scheduler that keeps the Goroutines context switched.

If a P for some m here has no work to do, there is no G, the runtime scheduler will try to spin that m for a little bit to keep it hot on the core. Because if that thread goes cold, the operating system will pull it off the core and put something else on. So it just spins a little bit to see if there will be another G coming in to get some work done.

This is how the scheduler works underneath. We have a P, attached to thread m. The operating system will do the scheduling. We don't want any more than cores we have. We don't need any more operating system threads than cores we have. If we have more threads than cores we have, all we do is put load on the operating system. We allow the Go's scheduler to make decisions on our Goroutines, keeping the least number of threads we need and hot all the time if we have work. The Go's scheduler is gonna look and feel preemptive even though we are calling a cooperating scheduler.

However, let's not think about how the scheduler works. Think the following way makes it easier for future development. Every single G, every Goroutine that is in runnable state, is running at the same time.

#### Language Mechanics

One of the most important things that we must do from day one is to write software that can startup and shutdown cleanly. This is very very important.

```go
package​ main

import​ (
    "fmt"
    "runtime"
    "sync"
)
```

init calls a function from the runtime package called GOMAXPROCS. This is also an environment variable, which is why it is all capitalized.

Prior to 1.5, when our Go program came up for the first time, it came up with just a single P, regardless of how many cores. The improvement that we made to the garbage collector and scheduler changed all that.

Allocate one logical processor for the scheduler to use.

```go
func​ ​init​() {
    runtime.GOMAXPROCS(​1​)
}

func​ ​main​() {
```

wg is used to manage concurrency. wg is set to its zero value. This is one of the very special types in Go that are usable in its zero value state. It is also called Asynchronous Counting Semaphore. It has three methods: Add, Done and Wait. n number of Goroutines can call this method at the same time and it's all serialized.

- Add keeps a count of how many Goroutines out there.
- Done decrements that count because some Goroutines are about to be terminated.
- Wait holds the program until that count goes back down to zero.

```go
    var​ wg sync.WaitGroup
```

We are creating 2 Goroutines. We rather call Add(1) and call it over and over again to increment by 1. If we don't know how many Goroutines that we are going to create, that is a smell.

```go
    wg.Add(​2​)

    fmt.Println(​"Start Goroutines"​)
```

Create a Goroutine from the uppercase function using anonymous function. We have a function decoration here with no name and being called by the () in the end. We are declaring and calling this function right here, inside of main. The big thing here is the keyword go in front of func().
We don't execute this function right now in series here. Go schedules that function to be a G, say G1, and load in some LRQ for our P. This is our first G. Remember, we want to think that every G that is in runnable state is running at the same time. Even though we have a single P, even though we have a single thread, we don't care. We are having 2 Goroutines running at the same time: main and G1.

```go
    go​ ​func​() {
        lowercase()
        wg.Done()
    }()
```

Wait for the Goroutines to finish. This is holding main from terminating because when the main terminates, our program terminates, regardless of what any other Goroutine is doing.

There is a golden rule here: We are not allowed to create a Goroutine unless we can tell when and how it terminates. Wait allows us to hold the program until the two other Goroutines report that they are done. It is gonna wait, count from 2 to 0. When it reaches 0, the scheduler will wake up the main Goroutine again and allow it to be terminated.

```go
    fmt.Println(​"Waiting To Finish"​) wg.Wait()
    wg.Wait()

    fmt.Println(​"\nTerminating Program"​)
}
```

lowercase displays the set of lowercase letters three times. Display the alphabet three times.

```go
func​ ​lowercase​() {
    for​ count := ​0​; count < ​3​; count++ {
        for​ r := ​'a'​; r <= ​'z'​; r++ {
            fmt.Printf(​"%c "​, r)
        }
    }
}
```

uppercase displays the set of uppercase letters three times. Display the alphabet three times.

```go
func​ ​uppercase​() {
    for​ count := ​0​; count < ​3​; count++ {
        for​ r := ​'A'​; r <= ​'Z'​; r++ {
            fmt.Printf(​"%c "​, r)
        }
    }
}
```

```
Start Goroutines
Waiting To Finish
A B C D E F G H I J K L M N O P Q R S T U V W X Y Z A B C D E F G H I J
K L M N O P Q R S T U V W X Y Z A B C D E F G H I J K L M N O P Q R S T
U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d
e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n
o p q r s t u v w x y z
Terminating Program
```

##### Sequence

We call the uppercase after lowercase but Go's scheduler chooses to call the lowercase first. Remember we are running on a single thread so there is only one Goroutine is executed at a given time here. We can't see that we are running concurrently that the uppercase runs before the lowercase. Everything starts and completes cleanly.

What if we forget to hold Wait?

We would see no output of uppercase and lowercase. This is pretty much a data race. It's a race to see the program terminate before the scheduler stops it and schedules another Goroutine to run. By not waiting, these Goroutines never get a chance to execute at all.

What if we forget to call Done?

Deadlock!

This is a very special thing in Go. When the runtime determines that all the Goroutines are there and can no longer move forward, it's gonna panic.

##### Goroutine time slicing

How the Go's scheduler, even though it is a cooperating scheduler (not preemptive), it looks and feels preemptive because the runtime scheduler is making all the decisions for us. It is not coming for us.

The program below will show us a context switch and how we can predict when the context switch is going to happen. It is using the same pattern that we've seen in the last file. The only difference is the printPrime function.

```go
package​ main

import​ (
    "fmt"
    "runtime"
    "sync"
)
```

Allocate one logical processor for the scheduler to use.

```go
func init() {
    runtime.GOMAXPROCX(1)
}
```

wg is used to manage concurrency.

```go
func​ ​main​() {
    var​ wg sync.WaitGroup
    wg.Add(​2​)

    fmt.Println(​"Create Goroutines"​)
```

Create the first goroutine and manage its lifecycle here.

```go
    go​ ​func​() {
        printPrime(​"A"​)
        wg.Done()
    }()
```

Create the second goroutine and manage its lifecycle here.

```go
    go​ ​func​() {
        printPrime(​"B"​)
        wg.Done()
    }()
```

Wait for the goroutines to finish.

```go
    fmt.Println(​"Waiting To Finish"​)
    wg.Wait()

    fmt.Println(​"Terminating Program"​)
}
```

printPrime displays prime numbers for the first 5000 numbers. printPrime is not special. It just requires a little bit more time to complete. When we run the program, what we will see are context switches at some point for some particular prime number. We cannot predict when the context switch will happen. That's why we say the Go's scheduler looks and feels very preemptive even though it is a cooperating scheduler.

```go
func​ ​printPrime​(prefix ​string​) {
next:
    for​ outer := ​2​; outer < ​5000​; outer++ {
        for​ inner := ​2​; inner < outer; inner++ {
            if​ outer%inner == ​0​ {
                continue​ next
            }
        }

        fmt.Printf(​"%s:%d\n"​, prefix, outer)
    }

    fmt.Println(​"Completed"​, prefix)
}
```

```
Create Goroutines
Waiting To Finish
B:2
B:3
B:5
B:7
B:11
B:13
B:17
B:19
...
B:4999
Completed B A:2
A:3
A:5
A:7
A:11
A:13
A:17
A:19
...
A:4999
Completed A
Terminating Program
```

##### Goroutines and parallelism

This programs show how Goroutines run in parallel. We are going to have 2 P with 2 m, and 2 Goroutines running in parallel on each m. This is still the same program that we are starting with. The only difference is that we are getting rid of the lowercase and uppercase function and putting their code directly inside Go's anonymous functions.

```go
package​ main
import​ (
    "fmt"
    "runtime"
    "sync"
)

func​ ​init​() {
```

Allocate 2 logical processors for the scheduler to use.

```go
    runtime.GOMAXPROCS(​2​)
}

func​ ​main​() {
```

wg is used to wait for the program to finish. Add a count of two, one for each goroutine.

```go
    var​ wg sync.WaitGroup
    wg.Add(​2​)

    fmt.Println(​"Start Goroutines"​)
```

Declare an anonymous function and create a goroutine. Display the alphabet three times.

```go
    go​ ​func​() {
        for​ count := ​0​; count < ​3​; count++ {
            for​ r := ​'a'​; r <= ​'z'​; r++ {
                fmt.Printf(​"%c "​, r)
            }
        }
```

Tell main we are done.

```go
        wg.Done()
    }()
```

Wait for the goroutines to finish.

```go
    fmt.Println(​"Waiting To Finish"​)
    wg.Wait()

    fmt.Println(​"\nTerminating Program"​)
}
```

Looking at the output, we can see a mix of uppercase or lowercase characters.

```
Start Goroutines
Waiting To Finish
a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j
k l m n o p A B C D E F G H I J K L M N O P Q R S q r s t u v w x y z a
b c d e f g h i j k l m n o p q r s t u v w x y z T U V W X Y Z A B C D
E F G H I J K L M N O P Q R S T U V W X Y Z A B C D E F G H I J K L M N
O P Q R S T U V W X Y Z
Terminating Program
```
